{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import gc\n",
    "gc.collect()\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "from IPython.display import clear_output\n",
    "#set_matplotlib_formats('retina')\n",
    "#from tqdm import tqdm\n",
    "#tqdm.pandas()\n",
    "import numpy as np\n",
    "from pyhive import presto\n",
    "from datetime import datetime, timedelta\n",
    "#from bson import ObjectId\n",
    "#from functools import reduce\n",
    "from sklearn.cluster import KMeans\n",
    "#from pymongo import MongoClient\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import date\n",
    "import json\n",
    "import re\n",
    "#import dtale\n",
    "#from h3 import h3\n",
    "# import pandasql as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabase_connection = presto.connect(\n",
    "        #host='bi-trino-2.serving.data.production.internal',\n",
    "        host='bi-trino.serving.data.production.internal',\n",
    "        #host='bi-presto.serving.data.production.internal',\n",
    "        #host='prime-trino.serving.data.production.internal',\n",
    "        #host=\"presto.processing.yoda.run\",\n",
    "        #host = \"processing-2.processing.data.production.internal\",\n",
    "        port=80,\n",
    "        protocol='http',\n",
    "        catalog ='hive',\n",
    "        username='praveen.u@rapido.bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mumbai 20230513\n"
     ]
    }
   ],
   "source": [
    "# from datetime import datetime\n",
    "# #yyyymmdd = pd.date_range(start='2023-05-10', end='2023-05-13').strftime('%Y%m%d').to_list()\n",
    "# yyyymmdd = pd.date_range(start='2023-05-13', end='2023-05-13').strftime('%Y%m%d').to_list()\n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# #for city in [\"Bangalore\",\"Hyderabad\",\"Delhi\",\"Jaipur\",\"Mumbai\",\"Pune\",\"Chennai\"]:\n",
    "# for city in [\"Mumbai\"]:\n",
    "#     for i in range(len(yyyymmdd)):\n",
    "#         dt = yyyymmdd[i]\n",
    "#         query1 = f\"\"\"\n",
    "#     select base.city,base.yyyymmdd, substr(hhmm,1,2) as hh,\n",
    "#     case \n",
    "#     when Offline_time <= 0.25 then '1. 0-15 Mins'\n",
    "#     when Offline_time <= 0.5 then '2. 15-30 Mins'\n",
    "#     when Offline_time <= 0.75 then '3. 30-45 Mins'\n",
    "#     when Offline_time <= 1 then '4. 45-60 Mins'\n",
    "#     when Offline_time <= 1.5 then '5. 1-1_1/2 Hrs'\n",
    "#     when Offline_time <= 2 then '6. 1_1/2-2 Hrs'\n",
    "#     when Offline_time <= 3 then '7. 2-3 Hrs'\n",
    "#     when Offline_time > 3 then '8. >3 Hrs'\n",
    "#     else '9. NA' end as Offline_time_Flag, \n",
    "#     Comp_Day_Affinity,\n",
    "#     count(distinct base.captain_id) as captain_count\n",
    "\n",
    "#     -- distinct Next_Status_Flag\n",
    "#     from(\n",
    "#         select *,\n",
    "#         -- ((cast(substr(cast(Next_Epoch as varchar),1,10) as bigint) - cast(substr(cast(epoch as varchar),1,10) as bigint))/(3600.00))\n",
    "#         case when Next_Epoch is NULL then to_unixtime(cast(REPLACE(cast(date_parse(yyyymmdd, '%Y%m%d') as varchar),'00:00:00.000','21:00:00.000') as timestamp)) else cast(substr(cast(Next_Epoch as varchar),1,10) as bigint) end as Next_Epoch2,\n",
    "#         case when Next_Status_Flag is NULL then 'NA' else Next_Status_Flag end as Next_Status_Flag2,\n",
    "#         (((case when Next_Epoch is NULL then to_unixtime(cast(REPLACE(cast(date_parse(yyyymmdd, '%Y%m%d') as varchar),'00:00:00.000','21:00:00.000') as timestamp)) else cast(substr(cast(Next_Epoch as varchar),1,10) as bigint) end) - (cast(substr(cast(epoch as varchar),1,10) as bigint)))/(3600.00)) as Offline_time\n",
    "#         from(\n",
    "#             select a.*,\n",
    "#             LEAD(Status_Flag,1) over (PARTITION BY captain_id ORDER BY epoch) as Next_Status_Flag,\n",
    "#             LEAD(epoch,1) over (PARTITION BY captain_id,Status_Flag ORDER BY epoch) as Next_Epoch\n",
    "#             from(\n",
    "#                     select t1.*, t2.city\n",
    "#                     from(\n",
    "#                             select case when status in (2,3,5,6,7,8) then 'Online' else 'Offline' end as Status_Flag,a.*\n",
    "\n",
    "#                             from  datasets.supplycursory_history a\n",
    "#                             where yyyymmdd = cast({dt} as varchar) \n",
    "#                             -- where yyyymmdd = '20230513' \n",
    "#                             and lower(trim(service)) like '%auto%'\n",
    "#                             -- and captain_id = '637df10983bccc342b905692'\n",
    "#                             and (cast(substr(hhmm,1,2) as int) >= 8 and cast(substr(hhmm,1,2) as int) <= 20)\n",
    "#                             and location in \n",
    "#                                         (Select distinct hex_id\n",
    "#                                         from datasets.city_cluster_hex \n",
    "#                                         where resolution = 8\n",
    "#                                         -- and city = 'Chennai'\n",
    "#                                         and city = '{city}'\n",
    "#                                         )\n",
    "#                     ) t1\n",
    "#                     left join (select distinct hex_id, city from datasets.city_cluster_hex where resolution = 8 and city = '{city}' ) t2\n",
    "#                     on t1.location = t2.hex_id\n",
    "#             ) as a\n",
    "\n",
    "#         ) as b\n",
    "#         where Status_Flag != case when Next_Status_Flag is NULL then 'NA' else Next_Status_Flag end\n",
    "#         and Status_Flag = 'Offline'\n",
    "#     ) as base\n",
    "\n",
    "#     left join (\n",
    "#     select captain_id,yyyymmdd, \n",
    "#     case \n",
    "#     when (Ola_MP_Flag+Ola_AF_Flag+Ola_EP_Flag) >= 2 and (Uber_MP_Flag+Uber_AF_Flag+Uber_EP_Flag) >= 2  then 'Both' \n",
    "#     when (Ola_MP_Flag+Ola_AF_Flag+Ola_EP_Flag) >= 2  then 'Ola' \n",
    "#     when (Uber_MP_Flag+Uber_AF_Flag+Uber_EP_Flag) >= 2  then 'Uber' else 'NP' end as Comp_Day_Affinity\n",
    "#     from (\n",
    "#         select captain_id,yyyymmdd, \n",
    "#         sum(case when time_period = 'morning_peak' and Ola_Hour_favorite >=3 then 1 else 0 end) as Ola_MP_Flag,\n",
    "#         sum(case when time_period = 'afternoon' and Ola_Hour_favorite >=4 then 1 else 0 end) as Ola_AF_Flag,\n",
    "#         sum(case when time_period = 'evening_peak' and Ola_Hour_favorite >=4 then 1 else 0 end) as Ola_EP_Flag,\n",
    "\n",
    "#         sum(case when time_period = 'morning_peak' and Uber_Hour_favorite >=3 then 1 else 0 end) as Uber_MP_Flag,\n",
    "#         sum(case when time_period = 'afternoon' and Uber_Hour_favorite >=4 then 1 else 0 end) as Uber_AF_Flag,\n",
    "#         sum(case when time_period = 'evening_peak' and Uber_Hour_favorite >=4 then 1 else 0 end) as Uber_EP_Flag\n",
    "\n",
    "#         from(\n",
    "#                 select captain_id,yyyymmdd,time_period,sum(Ola_Hour_favorite) as Ola_Hour_favorite,sum(Uber_Hour_favorite) as Uber_Hour_favorite\n",
    "#                 from(\n",
    "#                     select captain_id, yyyymmdd, substr(start_hour,1,2) as Hour, time_period,\n",
    "#                     sum(case when app_name = 'Ola' then Index_Flag else 0 end) as Ola_Hour_favorite,\n",
    "#                     sum(case when app_name = 'Uber' then Index_Flag else 0 end) as Uber_Hour_favorite\n",
    "#                     from hive.experiments.Auto_Competitor_App_usage_v2\n",
    "#                     where yyyymmdd = cast({dt} as varchar) \n",
    "#                     --  and yyyymmdd <= '20230501'\n",
    "#                     and time_period IN ('morning_peak','afternoon','evening_peak') \n",
    "#                     and city_name = '{city}'\n",
    "#                     group by 1,2,3,4\n",
    "#                 )\n",
    "#                 group by 1,2,3\n",
    "#             )\n",
    "#             group by 1,2\n",
    "#         ) t1\n",
    "#     ) day_affinity\n",
    "#     on base.captain_id = day_affinity.captain_id\n",
    "#     and base.yyyymmdd = day_affinity.yyyymmdd\n",
    "#     group by 1,2,3,4,5\n",
    "#         \"\"\"\n",
    "#         print(city,dt)\n",
    "#         t1 = pd.read_sql_query(query1, metabase_connection)\n",
    "#         df = pd.concat([t1, df], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5964, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = [\"Bangalore\",\"Hyderabad\",\"Delhi\",\"Jaipur\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['city'].isin(city)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7677, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Bring_Me_Back_On_Duty_Data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t1_dt=pd.DataFrame()\n",
    "\n",
    "# for i in pd.date_range('20230620','20230620'):\n",
    "\n",
    "#     query=\"\"\"\n",
    "#     select\n",
    "#             *\n",
    "#     from        \n",
    "#     (\n",
    "#         with v0 as \n",
    "\n",
    "#             (\n",
    "#                 select *\n",
    "#                 from        \n",
    "#                         (select \n",
    "#                                 order_id, yyyymmdd, city_name, order_type, captain_id, pickup_location_hex_8,\n",
    "#                                 event_type, order_status, spd_fraud_flag, service_obj_service_name as service_name,\n",
    "#                                 accept_to_pickup_distance, estimated_accept_to_pickup_distance as fm_osrm, eta,\n",
    "#                                 distance_final_distance, updated_hhmmss, updated_epoch, dispatch_global_priority,\n",
    "#                                 (case when yyyymmdd <= '20230704' then 'Pre Period' else 'Post Period' end) as period,\n",
    "\n",
    "#                                 (case when cast(substr(hhmmss,1,2) as real) >= 8 and cast(substr(hhmmss,1,2) as real) <= 11 then 'morning_peak'\n",
    "#                                 when cast(substr(hhmmss,1,2) as real) > 11 and cast(substr(hhmmss,1,2) as real) < 17 then 'afternoon'\n",
    "#                                 when cast(substr(hhmmss,1,2) as real) >= 17 and cast(substr(hhmmss,1,2) as real) <= 21 then 'evening_peak'\n",
    "#                                 when cast(substr(hhmmss,1,2) as real) >= 0 and cast(substr(hhmmss,1,2) as real) < 8 then 'rest_morning'\n",
    "#                                 else 'Rest_Evening' end) as time_bucket,\n",
    "#                                 row_number() over (partition by order_id order by updated_epoch desc) as rank_1,\n",
    "\n",
    "#                                 cardinality(array_remove(array_distinct(array_agg(captain_id) over (partition by order_id)), '')) as captains_pinged,\n",
    "#                                 array_agg(event_type) over (partition by order_id) as event_type_agg,\n",
    "#                                 cardinality(array_distinct(array_remove(split(replace(replace(replace(map_riders, '['), ']'), '\"'), ','), ''))) as map_riders_count, cancel_reason\n",
    "\n",
    "\n",
    "#                         from \n",
    "#                                 orders.order_logs_immutable\n",
    "#                         where \n",
    "#                                 yyyymmdd = '{dt}'\n",
    "#                                 and city_name in ('Pune','Hyderabad')\n",
    "#                                 and service_obj_service_name in ('Auto')\n",
    "#                         )\n",
    "#             ),\n",
    "\n",
    "#         v1 as \n",
    "#         (\n",
    "#             select city_name,test_ctrl, hex_id ,time_bucket\n",
    "#             from experiments_internal.auto_apr_fm_reduction_exp_230704 \n",
    "#             where city_name in ('Pune','Hyderabad')\n",
    "\n",
    "#         ),\n",
    "\n",
    "#     v2 as \n",
    "#         (select \n",
    "#             order_id as orderid, \n",
    "#             count(distinct rider_id_fc) as captain_count\n",
    "#         from\n",
    "#         (\n",
    "#         select \n",
    "#             order_id, rider_id, yyyymmdd, event_type,\n",
    "#             -- cardinality(array_remove(split(array_join(transform(cast(json_extract(data, '$.filteredCaptains') as array<json>), x->json_extract(x, '$.captain.riderId')), ','), ','), '')) as rider_fc_len,\n",
    "#             split(array_join(transform(cast(json_extract(data, '$.filteredCaptains') as array<json>), x->json_extract(x, '$.captain.riderId')), ','), ',') as rider_id_fc_list,\n",
    "#             split(array_join(transform(cast(json_extract(data, '$.filteredCaptains') as array<json>), x->json_extract(x, '$.filterType')), ','), ',') as filterType_list,\n",
    "#             service_detail_id, propagation_batch_id, updated_epoch,\n",
    "#             min(updated_epoch) over (partition by order_id, propagation_batch_id) as batch_epoch, updated_hhmmss,\n",
    "#             other_orders_in_propagation_for_rider, quarter_hour, riders, data\n",
    "#             -- , city_name, service_name\n",
    "#         from\n",
    "#             orders.dispatch_propagation_immutable \n",
    "#             -- a\n",
    "#             -- left join (select city_display_name as city_name, service_level as service_name, service_detail_id as service_detail_id_1\n",
    "#             -- from datasets.service_mapping) b on a.service_detail_id = b.service_detail_id_1\n",
    "#         where \n",
    "#             yyyymmdd = '{dt}'\n",
    "#             and service_detail_id in ('61769b50d21e19252c6f60e8','5ef2bc5b85846b775f97d170')\n",
    "#             and event_type in ('propagation_initiated_for_batch')\n",
    "\n",
    "#         ) cross join unnest(rider_id_fc_list, filterType_list) as t(rider_id_fc, filterType)\n",
    "#         where filterType in ('MMO_LIMIT_REACHED')\n",
    "#         group by 1\n",
    "\n",
    "#         )\n",
    "\n",
    "#     select \n",
    "#             v0.*, test_ctrl, captain_count\n",
    "#     from \n",
    "#             v0 \n",
    "#             left join v1 \n",
    "#             on v0.pickup_location_hex_8=v1.hex_id and v0.time_bucket = v1.time_bucket \n",
    "#             left join v2 \n",
    "#             on v0.order_id = v2.orderid\n",
    "            \n",
    "#     )\"\"\".format(dt=i.strftime('%Y%m%d'))\n",
    "\n",
    "#     df_test = pd.read_sql_query(query, metabase_connection)\n",
    "\n",
    "#     print(i)\n",
    "#     t1_dt=t1_dt.append(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metabase_connection = presto.connect(\n",
    "#         #host='bi-trino-2.serving.data.production.internal',\n",
    "#         #host='bi-trino.serving.data.production.internal',\n",
    "#         #host='bi-presto.serving.data.production.internal',\n",
    "#         #host='prime-trino.serving.data.production.internal',\n",
    "#         host=\"presto.processing.yoda.run\",\n",
    "#         port=80,\n",
    "#         protocol='http',\n",
    "#         catalog ='hive',\n",
    "#         username='praveen.u@rapido.bike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-23 00:00:00\n",
      "2023-07-24 00:00:00\n",
      "2023-07-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "t1_dt=pd.DataFrame()\n",
    "\n",
    "for i in pd.date_range('20230723','20230725'):\n",
    "\n",
    "    query=\"\"\"\n",
    "\n",
    "    with main as (\n",
    "\n",
    "                    select *,case when rw=1 and offline_to_online_time is not null then 'skip'\n",
    "                    else 'consider' end as rows_to_consider\n",
    "\n",
    "                    from\n",
    "                    (\n",
    "\n",
    "                    select *, row_number() over(partition by captain_id order by timestamp) rw \n",
    "                        from\n",
    "                        (\n",
    "                        select city,yyyymmdd,hh as hours,quarter_hour,a.captain_id,timestamp,date_format(from_unixtime(timestamp/1000), '%Y-%m-%d %h:%i:%s') timestamp_readable,\n",
    "                        case when (stored_status in ('2','3','5','6','7','8') and status = '9') then timestamp end as online_to_offline_time,\n",
    "                        case when status in ('2','3','5','6','7','8') and stored_status ='9'   then timestamp end as offline_to_online_time\n",
    "                        from hive.mismatch.rider_detail_changes as a \n",
    "\n",
    "                        join (\n",
    "\n",
    "                                select distinct city,captain_id \n",
    "                                from datasets.captain_metrics \n",
    "                                where yyyymmdd='{dt}' and city in ('Delhi') and service_mode = 'auto'\n",
    "\n",
    "                            ) b \n",
    "                                  on a.captain_id = b.captain_id\n",
    "\n",
    "                        where yyyymmdd='{dt}' and type='status'  and hh in ('08','09','10','11','12','13','17','18','19','20','21','22') \n",
    "\n",
    "                        ) \n",
    "                        where online_to_offline_time is not null or  offline_to_online_time is not null \n",
    "\n",
    "                        order by timestamp\n",
    "                    )\n",
    "                ),\n",
    "\n",
    "\n",
    "\n",
    "    table1 as \n",
    "\n",
    "            (\n",
    "            select city,yyyymmdd,hours,quarter_hour,captain_id,online_to_offline_time,\n",
    "            concat(captain_id,'_',cast(row_number() over(partition by captain_id order by online_to_offline_time) as varchar )) as unique_key\n",
    "\n",
    "            from main where rows_to_consider='consider' and online_to_offline_time is not null \n",
    "          ),\n",
    "\n",
    "     table2 as \n",
    "            (\n",
    "            select city,yyyymmdd,quarter_hour,captain_id,offline_to_online_time,\n",
    "            concat(captain_id,'_',cast(row_number() over(partition by captain_id order by offline_to_online_time) as varchar )) as unique_key\n",
    "\n",
    "            from main where rows_to_consider='consider' and offline_to_online_time is not null\n",
    "            ),\n",
    "\n",
    "\n",
    "    offline_caps as \n",
    "            (\n",
    "\n",
    "            select city,yyyymmdd,hours,count(distinct captain_id) as offline_captains\n",
    "            from main where online_to_offline_time is not null \n",
    "            group by 1,2,3 \n",
    "            ),\n",
    "    online_caps as \n",
    "\n",
    "            (\n",
    "            select city,yyyymmdd,hours,count(distinct captain_id) as online_captains\n",
    "            from main where offline_to_online_time is not null \n",
    "            group by 1,2,3 \n",
    "            ),\n",
    "\n",
    "    new_one as\n",
    "            ( \n",
    "                select * \n",
    "                from\n",
    "                (\n",
    "                    select a.city,a.yyyymmdd,a.hours,a.captain_id,online_to_offline_time,date_format(from_unixtime(online_to_offline_time/1000), '%Y-%m-%d %h:%i:%s') readable_online_to_offline_time,\n",
    "                        offline_to_online_time,date_format(from_unixtime(offline_to_online_time/1000), '%Y-%m-%d %h:%i:%s') readable_offline_to_online_time,\n",
    "                        a.unique_key,\n",
    "                        (offline_to_online_time-online_to_offline_time)/60000 as mins\n",
    "\n",
    "                        from table1 as a \n",
    "\n",
    "                        left join table2 as b \n",
    "\n",
    "                        on a.yyyymmdd=b.yyyymmdd and a.captain_id=b.captain_id and a.unique_key = b.unique_key\n",
    "                        order by unique_key  \n",
    "                )    \n",
    "                 where mins is not null and mins>=1 \n",
    "\n",
    "            ),\n",
    "\n",
    "    bring_back  as \n",
    "                (\n",
    "                    select distinct yyyymmdd,city,hh,epoch,\n",
    "                        date_format(from_unixtime(epoch/1000), '%Y-%m-%d %h:%i:%s') readable_epoch,\n",
    "                        event_props_user_id as caps_clicked_bring_back\n",
    "                        FROM\n",
    "                        (\n",
    "                        SELECT \n",
    "                          yyyymmdd, epoch,\n",
    "                          hh,\n",
    "                          event_props_city as city,\n",
    "                          event_props_user_id\n",
    "\n",
    "                        FROM \n",
    "                        clevertap.captain_bring_back_immutable\n",
    "                        WHERE yyyymmdd='{dt}' and event_props_city = 'Delhi'\n",
    "\n",
    "                )\n",
    "                where hh in ('08','09','10','11','12','13','17','18','19','20','21','22')\n",
    "\n",
    "\n",
    "            ),\n",
    "\n",
    "      system_trigger as (\n",
    "\n",
    "        select yyyymmdd,city,hh,count(distinct caps_clicked_bring_back) as brought_back_by_system_in_20mins\n",
    "        from\n",
    "        (\n",
    "            select distinct k1.yyyymmdd,k1.city,k1.hh,epoch,\n",
    "            date_format(from_unixtime(epoch/1000), '%Y-%m-%d %h:%i:%s') readable_epoch,\n",
    "            k1.event_props_user_id as caps_clicked_bring_back,trigger_epoch,trigger_readable_epoch,\n",
    "\n",
    "            row_number() over(partition by k1.event_props_user_id,trigger_readable_epoch order by epoch desc) as rw_num\n",
    "\n",
    "                FROM\n",
    "                (\n",
    "                SELECT \n",
    "                \n",
    "                yyyymmdd, epoch,hh,event_props_city as city,event_props_user_id\n",
    "\n",
    "                FROM \n",
    "                clevertap.captain_bring_back_immutable \n",
    "                WHERE \n",
    "                 yyyymmdd='{dt}' and event_props_city = 'Delhi'\n",
    "\n",
    "                ) as k1 \n",
    "\n",
    "            left join \n",
    "            (\n",
    "\n",
    "            select  yyyymmdd,hh,event_props_city,epoch as trigger_epoch,\n",
    "                    date_format(from_unixtime(epoch/1000), '%Y-%m-%d %h:%i:%s') trigger_readable_epoch,\n",
    "                    JSON_EXTRACT_SCALAR(event_props, '$.trigger') eventProps_trigger,event_props_user_id\n",
    "\n",
    "                    from  clevertap.captain_online_immutable \n",
    "                    where yyyymmdd='{dt}' and lower(event_props_city) in ('delhi') and hh in ('08','09','10','11','12','13','17','18','19','20','21','22')\n",
    "                    and JSON_EXTRACT_SCALAR(event_props, '$.trigger')='system'\n",
    "                    order by epoch \n",
    "            ) as k2 \n",
    "\n",
    "            on k1.yyyymmdd =k2.yyyymmdd and k1.hh =k2.hh and k1.event_props_user_id = k2.event_props_user_id\n",
    "\n",
    "            where k1.hh in ('08','09','10','11','12','13','17','18','19','20','21','22') and trigger_epoch>epoch\n",
    "\n",
    "            order by k1.hh,k1.event_props_user_id,epoch\n",
    "\n",
    "            ) where rw_num=1 \n",
    "\n",
    "            group by 1,2,3 \n",
    "            ),\n",
    "\n",
    "\n",
    "    final_one as\n",
    "    (            select city,yyyymmdd,hh,\n",
    "                count(distinct caps_clicked_bring_back) as caps_clicked,\n",
    "                count(caps_clicked_bring_back) as no_of_times_clicked,\n",
    "                count( case when mins<5 then captain_id end) as online_before_5mins,\n",
    "                count( case when mins>=5 and mins<10 then  captain_id end) as online_before_10mins,\n",
    "                count( case when mins>=10 and mins<15 then  captain_id end) as online_before_15mins,   \n",
    "                count( case when mins>=15 and mins<19 then  captain_id end) as online_before_19mins,\n",
    "                count( case when mins>=19 and mins<21 then  captain_id end) as online_around_20mins,\n",
    "                count( case when mins>=21 then  captain_id end) as online_after_20mins\n",
    "\n",
    "            FROM\n",
    "            (\n",
    "\n",
    "            select v1.yyyymmdd,v1.city,v1.hh,captain_id,caps_clicked_bring_back,online_to_offline_time,readable_online_to_offline_time,offline_to_online_time,readable_offline_to_online_time,mins,epoch,readable_epoch,\n",
    "            row_number() over(partition by captain_id,epoch order by epoch,offline_to_online_time) as rw_num\n",
    "\n",
    "            FROM bring_back v1 \n",
    "\n",
    "            left join new_one v2 \n",
    "\n",
    "            on v1.city = v2.city and v1.yyyymmdd =v2.yyyymmdd and v1.caps_clicked_bring_back = v2.captain_id and v1.hh =v2.hours\n",
    "\n",
    "            where offline_to_online_time>epoch -- to make sure we are checking post clicking bring back \n",
    "\n",
    "            order by hh,captain_id,epoch,offline_to_online_time\n",
    "\n",
    "            )\n",
    "\n",
    "            where rw_num =1 \n",
    "\n",
    "            group by 1,2,3 \n",
    "\n",
    "      )\n",
    "\n",
    "      select p1.city,p1.yyyymmdd,p1.hh,offline_captains,online_captains,caps_clicked,no_of_times_clicked,online_before_5mins,online_before_10mins,online_before_15mins,online_before_19mins,brought_back_by_system_in_20mins,\n",
    "      no_of_times_clicked - (online_before_5mins+online_before_10mins+online_before_15mins+online_before_19mins+brought_back_by_system_in_20mins) as not_brought_back_by_system\n",
    "\n",
    "      from final_one p1 \n",
    "      left join  system_trigger as p2 \n",
    "\n",
    "        on p1.city = p2.city and p1.yyyymmdd = p2.yyyymmdd and p1.hh = p2.hh \n",
    "\n",
    "      left join offline_caps as t2 \n",
    "        on p1.yyyymmdd =t2.yyyymmdd and p1.city = t2.city and p1.hh = t2.hours\n",
    "     left join online_caps as t3\n",
    "        on p1.yyyymmdd =t3.yyyymmdd and p1.city = t3.city and p1.hh = t3.hours\n",
    "\n",
    "\n",
    "    \"\"\".format(dt=i.strftime('%Y%m%d'))\n",
    "\n",
    "    df_test = pd.read_sql_query(query, metabase_connection)\n",
    "\n",
    "    print(i)\n",
    "    t1_dt=t1_dt.append(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_dt.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for getting any addition of rides or "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_dt_one=pd.DataFrame()\n",
    "\n",
    "for i in pd.date_range('20230723','20230723'):\n",
    "\n",
    "    query=\"\"\"with data1 as\n",
    "        ( \n",
    "        select city,captain_id,avg(total_login_hours) as pre_avg_total_login_hours,\n",
    "        avg(morning_peak_lhrs) as pre_morning_peak_lhrs,\n",
    "        avg(Evening_Peak_lhrs) as pre_Evening_Peak_lhrs,\n",
    "        avg(net_rides_taxi) as pre_RPR,\n",
    "        avg(morning_peak_net_rides) as pre_morning_peak_rpr,\n",
    "        avg(evening_peak_net_rides) as pre_evening_peak_rpr\n",
    "\n",
    "        from\n",
    "        (\n",
    "\n",
    "         select yyyymmdd,city,captain_id,total_login_hours,\n",
    "            (total_login_hour_08+ total_login_hour_09+ total_login_hour_10+total_login_hour_11+total_login_hour_12) as morning_peak_lhrs,\n",
    "            (total_login_hour_17+total_login_hour_18+total_login_hour_19+total_login_hour_20+total_login_hour_21) as  Evening_Peak_lhrs,\n",
    "            net_rides_taxi,\n",
    "            (net_rides_taxi_hour_08+net_rides_taxi_hour_09+net_rides_taxi_hour_10+net_rides_taxi_hour_11+net_rides_taxi_hour_12) as morning_peak_net_rides,\n",
    "            (net_rides_taxi_hour_17+net_rides_taxi_hour_18+net_rides_taxi_hour_19+net_rides_taxi_hour_20+net_rides_taxi_hour_21) as evening_peak_net_rides\n",
    "\n",
    "\n",
    "\n",
    "                from datasets.captain_metrics \n",
    "                where yyyymmdd>='20230703' and yyyymmdd<='20230717'  and service_mode='auto'\n",
    "                and lower(trim(city)) in ('bangalore','delhi')\n",
    "        )\n",
    "        group by 1,2 \n",
    "        ),\n",
    "\n",
    "    tab2 as \n",
    "        (\n",
    "\n",
    "        select yyyymmdd,city,caps_clicked_bring_back,post_avg_total_login_hours,post_morning_peak_lhrs,\n",
    "        post_Evening_Peak_lhrs,post_RPR,post_morning_peak_rpr,post_evening_peak_rpr\n",
    "\n",
    "        from\n",
    "        (\n",
    "         select distinct yyyymmdd,city,caps_clicked_bring_back,\n",
    "            from\n",
    "            (\n",
    "                select distinct k1.yyyymmdd,k1.city,k1.hh,epoch,\n",
    "                date_format(from_unixtime(epoch/1000), '%Y-%m-%d %h:%i:%s') readable_epoch,\n",
    "                k1.event_props_user_id as caps_clicked_bring_back,trigger_epoch,trigger_readable_epoch,\n",
    "\n",
    "                row_number() over(partition by k1.event_props_user_id,trigger_readable_epoch order by epoch desc) as rw_num\n",
    "\n",
    "                    FROM\n",
    "                    (\n",
    "                    SELECT \n",
    "\n",
    "                    yyyymmdd, epoch,hh,event_props_city as city,event_props_user_id\n",
    "\n",
    "                    FROM \n",
    "                    clevertap.captain_bring_back_immutable \n",
    "                    WHERE \n",
    "                     yyyymmdd='{dt}' and event_props_city = 'Delhi'\n",
    "\n",
    "                    ) as k1 \n",
    "\n",
    "                left join \n",
    "                (\n",
    "\n",
    "                select  yyyymmdd,hh,event_props_city,epoch as trigger_epoch,\n",
    "                        date_format(from_unixtime(epoch/1000), '%Y-%m-%d %h:%i:%s') trigger_readable_epoch,\n",
    "                        JSON_EXTRACT_SCALAR(event_props, '$.trigger') eventProps_trigger,event_props_user_id\n",
    "\n",
    "                        from  clevertap.captain_online_immutable \n",
    "                        where yyyymmdd='{dt}' and lower(event_props_city) in ('delhi') and hh in ('08','09','10','11','12','13','17','18','19','20','21','22')\n",
    "                        and JSON_EXTRACT_SCALAR(event_props, '$.trigger')='system'\n",
    "                        order by epoch \n",
    "                ) as k2 \n",
    "\n",
    "                on k1.yyyymmdd =k2.yyyymmdd and k1.hh =k2.hh and k1.event_props_user_id = k2.event_props_user_id\n",
    "\n",
    "                where k1.hh in ('08','09','10','11','12','13','17','18','19','20','21','22') and trigger_epoch>epoch\n",
    "\n",
    "                order by k1.hh,k1.event_props_user_id,epoch\n",
    "                )\n",
    "                where rw_num=1 \n",
    "\n",
    "            ) v1\n",
    "\n",
    "                left join\n",
    "                (\n",
    "                select city,captain_id,avg(total_login_hours) as post_avg_total_login_hours,\n",
    "                avg(morning_peak_lhrs) as post_morning_peak_lhrs,\n",
    "                avg(Evening_Peak_lhrs) as post_Evening_Peak_lhrs,\n",
    "                avg(net_rides_taxi) as post_RPR,\n",
    "                avg(morning_peak_net_rides) as post_morning_peak_rpr,\n",
    "                avg(evening_peak_net_rides) as post_evening_peak_rpr\n",
    "\n",
    "                from\n",
    "                (\n",
    "\n",
    "                 select yyyymmdd,city,captain_id,total_login_hours,\n",
    "                    (total_login_hour_08+ total_login_hour_09+ total_login_hour_10+total_login_hour_11+total_login_hour_12) as morning_peak_lhrs,\n",
    "                    (total_login_hour_17+total_login_hour_18+total_login_hour_19+total_login_hour_20+total_login_hour_21) as  Evening_Peak_lhrs,\n",
    "                    net_rides_taxi,\n",
    "                    (net_rides_taxi_hour_08+net_rides_taxi_hour_09+net_rides_taxi_hour_10+net_rides_taxi_hour_11+net_rides_taxi_hour_12) as morning_peak_net_rides,\n",
    "                    (net_rides_taxi_hour_17+net_rides_taxi_hour_18+net_rides_taxi_hour_19+net_rides_taxi_hour_20+net_rides_taxi_hour_21) as evening_peak_net_rides\n",
    "\n",
    "\n",
    "\n",
    "                        from datasets.captain_metrics \n",
    "                        where yyyymmdd='{dt}' and service_mode='auto'\n",
    "                        and lower(trim(city)) in ('delhi')\n",
    "                )\n",
    "                group by 1,2 \n",
    "\n",
    "\n",
    "                ) as v2\n",
    "\n",
    "            on v1.yyyymmdd = v2.yyyymmdd and v1.caps_clicked_bring_back = v2.captain_id\n",
    "\n",
    "    )\n",
    "\n",
    "    select\n",
    "    tab2.yyyymmdd,tab2.city,caps_clicked_bring_back,\n",
    "    pre_avg_total_login_hours,pre_morning_peak_lhrs,pre_Evening_Peak_lhrs,pre_RPR,pre_morning_peak_rpr,pre_evening_peak_rpr\n",
    "    post_avg_total_login_hours,post_morning_peak_lhrs,post_Evening_Peak_lhrs,post_RPR,post_morning_peak_rpr,post_evening_peak_rpr\n",
    "    from \n",
    "    tab2\n",
    "    join data1\n",
    "\n",
    "    on tab2.city = data1.city and tab2.captain_id = data1.caps_clicked_bring_back\n",
    "\n",
    "\n",
    "    \"\"\".format(dt=i.strftime('%Y%m%d'))\n",
    "\n",
    "    df_test = pd.read_sql_query(query, metabase_connection)\n",
    "\n",
    "    print(i)\n",
    "    t1_dt_one=t1_dt_one.append(df_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
